{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "heavy-cinema",
   "metadata": {},
   "source": [
    "# Checking which device the code is running on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aware-acoustic",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 3296877975321716312\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 7810842624\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 4539425842461911283\n",
      "physical_device_desc: \"device: 0, name: GeForce RTX 3080, pci bus id: 0000:09:00.0, compute capability: 8.6\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "respiratory-angel",
   "metadata": {},
   "source": [
    "# Optional Installs and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cardiovascular-carrier",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install scipy\n",
    "# !pip install pandas\n",
    "# !pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "pursuant-ancient",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from tensorflow.keras.layers import Input, Conv2D, Flatten, Dense, MaxPool2D, BatchNormalization, GlobalAveragePooling2D, AveragePooling2D, Dropout, Activation\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "import numpy as np\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extreme-burning",
   "metadata": {},
   "source": [
    "# Utility Functions for Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "regulation-array",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(img_filepath):\n",
    "    directory = 'chimp_faces/'\n",
    "    img_file = tf.io.read_file(directory + img_filepath)\n",
    "    \n",
    "    #First attempt:\n",
    "    #img = tf.image.decode_image(img, dtype=tf.float32)\n",
    "    \n",
    "    #Second attempt:\n",
    "    img_tensor_uint8  = tf.io.decode_png(img_file)\n",
    "    img_tensor_float32 = tf.cast(img_tensor_uint8, tf.float32)\n",
    "    return img_tensor_float32\n",
    "\n",
    "def augment(img):\n",
    "    #insert optional augmentations here\n",
    "    if tf.random.uniform((), minval=0, maxval=1) < 0.1: #Ten percent probability\n",
    "        img = tf.image.random_brightness(img, max_delta=0.1)\n",
    "#     if tf.random.uniform((), minval=0, maxval=1) < 0.1: #Ten percent probability\n",
    "#         img = tf.image.random_contrast(img, lower=0.1, upper=0.2)\n",
    "    img = tf.image.random_flip_left_right(img)\n",
    "    return img\n",
    "\n",
    "def normalize01(img):\n",
    "    max = 255\n",
    "    min = 0\n",
    "    result = tf.math.subtract(img, min)\n",
    "    norm_image = tf.math.divide(result, (max - min))\n",
    "    return norm_image\n",
    "\n",
    "def resize(img, target_h=224, target_w=224):\n",
    "    # resize with 0-padding\n",
    "    img = tf.image.resize_with_pad(img,\n",
    "                                     target_h,\n",
    "                                     target_w,\n",
    "                                     method=tf.image.ResizeMethod.BILINEAR,\n",
    "                                     antialias=False\n",
    "                                     )\n",
    "    return img\n",
    "\n",
    "\n",
    "def onehot_labels(labels):\n",
    "    #encode labels to integer\n",
    "    label_encoder = LabelEncoder()\n",
    "    integer_encoded_labels = label_encoder.fit_transform(labels)\n",
    "    #encode labels to one_hot\n",
    "    onehot_encoder = OneHotEncoder(sparse=False)\n",
    "    integer_encoded_labels = integer_encoded_labels.reshape(len(integer_encoded_labels), 1)\n",
    "    onehot_encoded_labels = onehot_encoder.fit_transform(integer_encoded_labels)\n",
    "    return onehot_encoded_labels\n",
    "\n",
    "def load_dataset_split(filename, training_set):\n",
    "    annotations_directory = 'Freytag_dataset_splits/compiled_skf/'\n",
    "    df = pd.read_csv(annotations_directory + filename)\n",
    "    filepaths = df['filename'].values\n",
    "    names = df['name'].values\n",
    "    ds_names = tf.data.Dataset.from_tensor_slices(onehot_labels(names))\n",
    "\n",
    "    ds_images = tf.data.Dataset.from_tensor_slices(filepaths)\n",
    "    \n",
    "    ds_images = ds_images.map(read_image)    \n",
    "    \n",
    "    ds_images = ds_images.map(normalize01)\n",
    "    ds_images = ds_images.map(resize)\n",
    "    if training_set==True:\n",
    "        ds_images = ds_images.map(augment)\n",
    "\n",
    "    dataset = tf.data.Dataset.zip((ds_images, ds_names))\n",
    "    dataset = dataset.shuffle(buffer_size=10000)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "graduate-tackle",
   "metadata": {},
   "source": [
    "# Loading with Freytag Dataset Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "daily-cancellation",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height, img_width = (224, 224)\n",
    "batch_size = 32\n",
    "train_ds_list = []\n",
    "test_ds_list = []\n",
    "#Each split has 86 distinct names\n",
    "\n",
    "#Loading different training splits\n",
    "ds_train1 = load_dataset_split('train_1.csv', training_set=True)\n",
    "ds_train2 = load_dataset_split('train_2.csv', training_set=True)\n",
    "ds_train3 = load_dataset_split('train_3.csv', training_set=True)\n",
    "ds_train4 = load_dataset_split('train_4.csv', training_set=True)\n",
    "ds_train5 = load_dataset_split('train_5.csv', training_set=True)\n",
    "train_ds_list.append(ds_train1)\n",
    "train_ds_list.append(ds_train2)\n",
    "train_ds_list.append(ds_train3)\n",
    "train_ds_list.append(ds_train4)\n",
    "train_ds_list.append(ds_train5)\n",
    "\n",
    "\n",
    "#Loading different test splits\n",
    "ds_test1 = load_dataset_split('test_1.csv', training_set=False)\n",
    "ds_test2 = load_dataset_split('test_2.csv', training_set=False)\n",
    "ds_test3 = load_dataset_split('test_3.csv', training_set=False)\n",
    "ds_test4 = load_dataset_split('test_4.csv', training_set=False)\n",
    "ds_test5 = load_dataset_split('test_5.csv', training_set=False)\n",
    "test_ds_list.append(ds_test1)\n",
    "test_ds_list.append(ds_test2)\n",
    "test_ds_list.append(ds_test3)\n",
    "test_ds_list.append(ds_test4)\n",
    "test_ds_list.append(ds_test5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "irish-major",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_model(num_classes=86, weightsname='imagenet', trainable=False, layers_unfrozen=0):\n",
    "    \"\"\"\n",
    "    set trainable to True to retrain certain layers. (ResNet50 has 175 layers.)\n",
    "    \n",
    "    With trainable at True, layers_unfrozen = 0 (default value) unfreezes ALL layers in ResNet50\n",
    "    for training.\n",
    "    \n",
    "    layers_unfrozen set to any number other than zero denotes the number of layers of ResNet50 to \n",
    "    unfreeze starting from the bottom most layer (N minus layers_unfrozen)\n",
    "    \"\"\"\n",
    "\n",
    "    base_model = ResNet50(include_top=False, weights=weightsname)\n",
    "    input_layer = tf.keras.Input(shape=(img_height, img_width, 3))\n",
    "    x = base_model(input_layer, training=trainable)\n",
    "    \n",
    "    \n",
    "    if trainable == False:\n",
    "        for layer in base_model.layers:\n",
    "            layer.trainable = False\n",
    "    else: #trainable == True\n",
    "        if layers_unfrozen!=0:\n",
    "            #freeze only a set number of layers\n",
    "            layers_frozen = len(base_model.layers) - layers_unfrozen\n",
    "            for i in range(layers_frozen):\n",
    "                base_model.layers[i].trainable = False\n",
    "        else:\n",
    "            #leave all layers unfrozen\n",
    "            pass\n",
    "        \n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    predictions = Dense(num_classes, activation='softmax')(x)\n",
    "    model = Model(inputs=input_layer, outputs=predictions)\n",
    "    #model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics = ['accuracy'])\n",
    "    return model\n",
    "\n",
    "def train(trainable_or_not, unfrozen_layers_count, epoch_count, save_directory, unlabeled_model_name, train_datasets, test_datasets):\n",
    "    result_list = []\n",
    "    loss_list = []\n",
    "    accuracy_list = []\n",
    "    for i in range(5):\n",
    "        print(\"Split \" + str(i+1) + \":\")\n",
    "        #Make sure unlabeled_model_name DOESN'T CONTAIN '.h5'\n",
    "        labeled_model_name = 'model' + str(i+1) + '-' + unlabeled_model_name + '.h5'\n",
    "        #Make sure save_directory STARTS WITHOUT a forrward slash '/' and ENDS WITH a forward slash '/'\n",
    "        save_path = save_directory + labeled_model_name\n",
    "        model = generate_model(trainable=trainable_or_not, layers_unfrozen=unfrozen_layers_count)\n",
    "        model.fit(train_datasets[i], epochs=epoch_count)\n",
    "        print(\"Test Split Evaluation:\")\n",
    "        result = model.evaluate(test_datasets[i])\n",
    "        result_list.append(result)\n",
    "        model.save(save_path, save_format='tf')\n",
    "    for result in result_list:\n",
    "        loss_list.append(result[0])\n",
    "        accuracy_list.append(result[1])\n",
    "    print(\"\\n\\nAverage Loss: \", sum(loss_list)/len(loss_list))\n",
    "    print(\"Average Accuracy: \", sum(accuracy_list)/len(accuracy_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smooth-music",
   "metadata": {},
   "source": [
    "# ResNet50 (ImageNet) Transfer Learning with no Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "acquired-scanning",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 1:\n",
      "Epoch 1/10\n",
      "162/162 [==============================] - 16s 38ms/step - loss: 4.3942 - accuracy: 0.0389\n",
      "Epoch 2/10\n",
      "162/162 [==============================] - 9s 37ms/step - loss: 4.2364 - accuracy: 0.0491\n",
      "Epoch 3/10\n",
      "162/162 [==============================] - 9s 37ms/step - loss: 4.1897 - accuracy: 0.0544\n",
      "Epoch 4/10\n",
      "162/162 [==============================] - 9s 37ms/step - loss: 4.1728 - accuracy: 0.0479\n",
      "Epoch 5/10\n",
      "162/162 [==============================] - 9s 37ms/step - loss: 4.1375 - accuracy: 0.0583\n",
      "Epoch 6/10\n",
      "162/162 [==============================] - 9s 38ms/step - loss: 4.1095 - accuracy: 0.0587\n",
      "Epoch 7/10\n",
      "162/162 [==============================] - 9s 38ms/step - loss: 4.0796 - accuracy: 0.0647\n",
      "Epoch 8/10\n",
      "162/162 [==============================] - 9s 37ms/step - loss: 4.0855 - accuracy: 0.0533\n",
      "Epoch 9/10\n",
      "162/162 [==============================] - 10s 40ms/step - loss: 4.0632 - accuracy: 0.0584\n",
      "Epoch 10/10\n",
      "162/162 [==============================] - 9s 37ms/step - loss: 4.0474 - accuracy: 0.0623\n",
      "Test Split Evaluation:\n",
      "42/42 [==============================] - 3s 44ms/step - loss: 4.0632 - accuracy: 0.0594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RGWLYD\\miniconda3\\envs\\tfgpu\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 2:\n",
      "Epoch 1/10\n",
      "162/162 [==============================] - 12s 38ms/step - loss: 4.4036 - accuracy: 0.0435\n",
      "Epoch 2/10\n",
      "162/162 [==============================] - 10s 38ms/step - loss: 4.2276 - accuracy: 0.0438\n",
      "Epoch 3/10\n",
      "162/162 [==============================] - 10s 43ms/step - loss: 4.1995 - accuracy: 0.0542\n",
      "Epoch 4/10\n",
      "162/162 [==============================] - 10s 38ms/step - loss: 4.1559 - accuracy: 0.0514\n",
      "Epoch 5/10\n",
      "162/162 [==============================] - 10s 38ms/step - loss: 4.1021 - accuracy: 0.0638\n",
      "Epoch 6/10\n",
      "162/162 [==============================] - 10s 38ms/step - loss: 4.0834 - accuracy: 0.0562\n",
      "Epoch 7/10\n",
      "162/162 [==============================] - 10s 38ms/step - loss: 4.0779 - accuracy: 0.0634\n",
      "Epoch 8/10\n",
      "162/162 [==============================] - 10s 38ms/step - loss: 4.0467 - accuracy: 0.0582\n",
      "Epoch 9/10\n",
      "162/162 [==============================] - 10s 38ms/step - loss: 4.0330 - accuracy: 0.0634\n",
      "Epoch 10/10\n",
      "162/162 [==============================] - 10s 38ms/step - loss: 4.0359 - accuracy: 0.0574\n",
      "Test Split Evaluation:\n",
      "42/42 [==============================] - 3s 37ms/step - loss: 4.0570 - accuracy: 0.0609\n",
      "Split 3:\n",
      "Epoch 1/10\n",
      "162/162 [==============================] - 12s 38ms/step - loss: 4.3947 - accuracy: 0.0330\n",
      "Epoch 2/10\n",
      "162/162 [==============================] - 10s 38ms/step - loss: 4.2119 - accuracy: 0.0566\n",
      "Epoch 3/10\n",
      "162/162 [==============================] - 10s 38ms/step - loss: 4.1994 - accuracy: 0.0579\n",
      "Epoch 4/10\n",
      "162/162 [==============================] - 10s 38ms/step - loss: 4.1588 - accuracy: 0.0518\n",
      "Epoch 5/10\n",
      "162/162 [==============================] - 10s 38ms/step - loss: 4.1380 - accuracy: 0.0539\n",
      "Epoch 6/10\n",
      "162/162 [==============================] - 10s 37ms/step - loss: 4.0949 - accuracy: 0.0580\n",
      "Epoch 7/10\n",
      "162/162 [==============================] - 10s 37ms/step - loss: 4.0794 - accuracy: 0.0586\n",
      "Epoch 8/10\n",
      "162/162 [==============================] - 10s 37ms/step - loss: 4.0707 - accuracy: 0.0589\n",
      "Epoch 9/10\n",
      "162/162 [==============================] - 10s 39ms/step - loss: 4.0569 - accuracy: 0.0610\n",
      "Epoch 10/10\n",
      "162/162 [==============================] - 10s 38ms/step - loss: 4.0512 - accuracy: 0.0575\n",
      "Test Split Evaluation:\n",
      "42/42 [==============================] - 3s 37ms/step - loss: 4.0603 - accuracy: 0.0563\n",
      "Split 4:\n",
      "Epoch 1/10\n",
      "162/162 [==============================] - 12s 38ms/step - loss: 4.4019 - accuracy: 0.0441\n",
      "Epoch 2/10\n",
      "162/162 [==============================] - 10s 37ms/step - loss: 4.2180 - accuracy: 0.0517\n",
      "Epoch 3/10\n",
      "162/162 [==============================] - 10s 38ms/step - loss: 4.2049 - accuracy: 0.0520\n",
      "Epoch 4/10\n",
      "162/162 [==============================] - 10s 37ms/step - loss: 4.1604 - accuracy: 0.0617\n",
      "Epoch 5/10\n",
      "162/162 [==============================] - 10s 37ms/step - loss: 4.1311 - accuracy: 0.0534\n",
      "Epoch 6/10\n",
      "162/162 [==============================] - 10s 37ms/step - loss: 4.1066 - accuracy: 0.0567\n",
      "Epoch 7/10\n",
      "162/162 [==============================] - 10s 37ms/step - loss: 4.0877 - accuracy: 0.0551\n",
      "Epoch 8/10\n",
      "162/162 [==============================] - 10s 37ms/step - loss: 4.0676 - accuracy: 0.0566\n",
      "Epoch 9/10\n",
      "162/162 [==============================] - 10s 37ms/step - loss: 4.0622 - accuracy: 0.0603\n",
      "Epoch 10/10\n",
      "162/162 [==============================] - 10s 37ms/step - loss: 4.0523 - accuracy: 0.0610\n",
      "Test Split Evaluation:\n",
      "42/42 [==============================] - 3s 37ms/step - loss: 4.0582 - accuracy: 0.0526\n",
      "Split 5:\n",
      "Epoch 1/10\n",
      "162/162 [==============================] - 12s 38ms/step - loss: 4.4006 - accuracy: 0.0418\n",
      "Epoch 2/10\n",
      "162/162 [==============================] - 10s 40ms/step - loss: 4.2231 - accuracy: 0.0530\n",
      "Epoch 3/10\n",
      "162/162 [==============================] - 10s 38ms/step - loss: 4.2040 - accuracy: 0.0540\n",
      "Epoch 4/10\n",
      "162/162 [==============================] - 10s 37ms/step - loss: 4.1774 - accuracy: 0.0581\n",
      "Epoch 5/10\n",
      "162/162 [==============================] - 10s 37ms/step - loss: 4.1349 - accuracy: 0.0587\n",
      "Epoch 6/10\n",
      "162/162 [==============================] - 10s 37ms/step - loss: 4.0865 - accuracy: 0.0643\n",
      "Epoch 7/10\n",
      "162/162 [==============================] - 10s 38ms/step - loss: 4.0805 - accuracy: 0.0612\n",
      "Epoch 8/10\n",
      "162/162 [==============================] - 10s 37ms/step - loss: 4.0597 - accuracy: 0.0578\n",
      "Epoch 9/10\n",
      "162/162 [==============================] - 10s 37ms/step - loss: 4.0382 - accuracy: 0.0626\n",
      "Epoch 10/10\n",
      "162/162 [==============================] - 10s 37ms/step - loss: 4.0294 - accuracy: 0.0616\n",
      "Test Split Evaluation:\n",
      "42/42 [==============================] - 3s 36ms/step - loss: 4.0517 - accuracy: 0.0594\n",
      "\n",
      "\n",
      "Average Loss:  4.058075332641602\n",
      "Average Accuracy:  0.057700976729393005\n"
     ]
    }
   ],
   "source": [
    "train(trainable_or_not=False, unfrozen_layers_count=0, epoch_count=10, save_directory='saved_models/no-finetune/',\n",
    "      unlabeled_model_name='no-finetune', train_datasets=train_ds_list, test_datasets=test_ds_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "derived-ordinance",
   "metadata": {},
   "source": [
    "# ResNet50 (ImageNet) Transfer Learning with Fine Tuning\n",
    "Keep first 15 layeres of base model frozen from training and 160 unfrozen for training for optimal results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "chemical-motel",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 1:\n",
      "Epoch 1/10\n",
      "162/162 [==============================] - 27s 111ms/step - loss: 4.1121 - accuracy: 0.0648\n",
      "Epoch 2/10\n",
      "162/162 [==============================] - 21s 107ms/step - loss: 2.8588 - accuracy: 0.2021\n",
      "Epoch 3/10\n",
      "162/162 [==============================] - 21s 108ms/step - loss: 2.2951 - accuracy: 0.3157\n",
      "Epoch 4/10\n",
      "162/162 [==============================] - 21s 107ms/step - loss: 1.9425 - accuracy: 0.4189\n",
      "Epoch 5/10\n",
      "162/162 [==============================] - 21s 108ms/step - loss: 1.6240 - accuracy: 0.4984\n",
      "Epoch 6/10\n",
      "162/162 [==============================] - 21s 107ms/step - loss: 1.3146 - accuracy: 0.5889\n",
      "Epoch 7/10\n",
      "162/162 [==============================] - 21s 108ms/step - loss: 1.0503 - accuracy: 0.6767\n",
      "Epoch 8/10\n",
      "162/162 [==============================] - 21s 107ms/step - loss: 0.7909 - accuracy: 0.7561\n",
      "Epoch 9/10\n",
      "162/162 [==============================] - 21s 108ms/step - loss: 0.6694 - accuracy: 0.7957\n",
      "Epoch 10/10\n",
      "162/162 [==============================] - 21s 107ms/step - loss: 0.6042 - accuracy: 0.8081\n",
      "Test Split Evaluation:\n",
      "42/42 [==============================] - 4s 45ms/step - loss: 1.1631 - accuracy: 0.6754\n",
      "Split 2:\n",
      "Epoch 1/10\n",
      "162/162 [==============================] - 25s 108ms/step - loss: 4.1571 - accuracy: 0.0604\n",
      "Epoch 2/10\n",
      "162/162 [==============================] - 21s 108ms/step - loss: 2.9715 - accuracy: 0.1958\n",
      "Epoch 3/10\n",
      "162/162 [==============================] - 21s 108ms/step - loss: 2.5732 - accuracy: 0.2760\n",
      "Epoch 4/10\n",
      "162/162 [==============================] - 21s 108ms/step - loss: 2.1283 - accuracy: 0.3485\n",
      "Epoch 5/10\n",
      "162/162 [==============================] - 21s 108ms/step - loss: 1.9073 - accuracy: 0.4130\n",
      "Epoch 6/10\n",
      "162/162 [==============================] - 21s 109ms/step - loss: 1.5615 - accuracy: 0.5094\n",
      "Epoch 7/10\n",
      "162/162 [==============================] - 21s 108ms/step - loss: 1.3080 - accuracy: 0.5943\n",
      "Epoch 8/10\n",
      "162/162 [==============================] - 21s 108ms/step - loss: 1.0953 - accuracy: 0.6578\n",
      "Epoch 9/10\n",
      "162/162 [==============================] - 21s 108ms/step - loss: 0.8695 - accuracy: 0.7205\n",
      "Epoch 10/10\n",
      "162/162 [==============================] - 21s 108ms/step - loss: 0.8438 - accuracy: 0.7422\n",
      "Test Split Evaluation:\n",
      "42/42 [==============================] - 4s 45ms/step - loss: 1.3089 - accuracy: 0.6266\n",
      "Split 3:\n",
      "Epoch 1/10\n",
      "162/162 [==============================] - 25s 107ms/step - loss: 3.8353 - accuracy: 0.1041\n",
      "Epoch 2/10\n",
      "162/162 [==============================] - 21s 108ms/step - loss: 2.5715 - accuracy: 0.2619\n",
      "Epoch 3/10\n",
      "162/162 [==============================] - 21s 108ms/step - loss: 1.9989 - accuracy: 0.3983s - loss: 2.0013 - accuracy\n",
      "Epoch 4/10\n",
      "162/162 [==============================] - 21s 107ms/step - loss: 1.5854 - accuracy: 0.5142\n",
      "Epoch 5/10\n",
      "162/162 [==============================] - 21s 109ms/step - loss: 1.2462 - accuracy: 0.6146\n",
      "Epoch 6/10\n",
      "162/162 [==============================] - 21s 108ms/step - loss: 1.0634 - accuracy: 0.6724\n",
      "Epoch 7/10\n",
      "162/162 [==============================] - 21s 108ms/step - loss: 0.9467 - accuracy: 0.7066\n",
      "Epoch 8/10\n",
      "162/162 [==============================] - 21s 108ms/step - loss: 0.7202 - accuracy: 0.7845\n",
      "Epoch 9/10\n",
      "162/162 [==============================] - 21s 108ms/step - loss: 0.4269 - accuracy: 0.8704\n",
      "Epoch 10/10\n",
      "162/162 [==============================] - 21s 106ms/step - loss: 0.4046 - accuracy: 0.8760\n",
      "Test Split Evaluation:\n",
      "42/42 [==============================] - 4s 44ms/step - loss: 1.1929 - accuracy: 0.6724\n",
      "Split 4:\n",
      "Epoch 1/10\n",
      "162/162 [==============================] - 24s 106ms/step - loss: 3.8514 - accuracy: 0.1122\n",
      "Epoch 2/10\n",
      "162/162 [==============================] - 21s 106ms/step - loss: 2.5655 - accuracy: 0.2578\n",
      "Epoch 3/10\n",
      "162/162 [==============================] - 21s 106ms/step - loss: 2.0030 - accuracy: 0.3940\n",
      "Epoch 4/10\n",
      "162/162 [==============================] - 21s 106ms/step - loss: 1.5825 - accuracy: 0.5240\n",
      "Epoch 5/10\n",
      "162/162 [==============================] - 21s 106ms/step - loss: 1.2350 - accuracy: 0.6223\n",
      "Epoch 6/10\n",
      "162/162 [==============================] - 21s 106ms/step - loss: 1.0208 - accuracy: 0.6900\n",
      "Epoch 7/10\n",
      "162/162 [==============================] - 21s 106ms/step - loss: 0.8558 - accuracy: 0.7322\n",
      "Epoch 8/10\n",
      "162/162 [==============================] - 21s 106ms/step - loss: 0.6608 - accuracy: 0.7930\n",
      "Epoch 9/10\n",
      "162/162 [==============================] - 21s 106ms/step - loss: 0.5788 - accuracy: 0.8199\n",
      "Epoch 10/10\n",
      "162/162 [==============================] - 21s 106ms/step - loss: 0.4820 - accuracy: 0.8554\n",
      "Test Split Evaluation:\n",
      "42/42 [==============================] - 4s 44ms/step - loss: 1.1350 - accuracy: 0.6867\n",
      "Split 5:\n",
      "Epoch 1/10\n",
      "162/162 [==============================] - 25s 106ms/step - loss: 3.9526 - accuracy: 0.0985\n",
      "Epoch 2/10\n",
      "162/162 [==============================] - 21s 105ms/step - loss: 2.6234 - accuracy: 0.2613\n",
      "Epoch 3/10\n",
      "162/162 [==============================] - 21s 106ms/step - loss: 2.0773 - accuracy: 0.3697\n",
      "Epoch 4/10\n",
      "162/162 [==============================] - 21s 106ms/step - loss: 1.6718 - accuracy: 0.4962\n",
      "Epoch 5/10\n",
      "162/162 [==============================] - 21s 106ms/step - loss: 1.3390 - accuracy: 0.5878\n",
      "Epoch 6/10\n",
      "162/162 [==============================] - 21s 106ms/step - loss: 1.1806 - accuracy: 0.6479\n",
      "Epoch 7/10\n",
      "162/162 [==============================] - 21s 106ms/step - loss: 0.8179 - accuracy: 0.7424\n",
      "Epoch 8/10\n",
      "162/162 [==============================] - 21s 106ms/step - loss: 0.7138 - accuracy: 0.7827\n",
      "Epoch 9/10\n",
      "162/162 [==============================] - 21s 106ms/step - loss: 0.5543 - accuracy: 0.8327\n",
      "Epoch 10/10\n",
      "162/162 [==============================] - 21s 106ms/step - loss: 0.3310 - accuracy: 0.8994\n",
      "Test Split Evaluation:\n",
      "42/42 [==============================] - 4s 44ms/step - loss: 1.1411 - accuracy: 0.6890\n",
      "\n",
      "\n",
      "Average Loss:  1.1881785631179809\n",
      "Average Accuracy:  0.6700225472450256\n"
     ]
    }
   ],
   "source": [
    "train(trainable_or_not=True, unfrozen_layers_count=160, epoch_count=10, save_directory='saved_models/unfreeze160/',\n",
    "      unlabeled_model_name='N-160', train_datasets=train_ds_list, test_datasets=test_ds_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "driven-elizabeth",
   "metadata": {},
   "source": [
    "# Model Loading and Evaluating (No Training)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "novel-clark",
   "metadata": {},
   "source": [
    "When using this section, restart the kernel and do not run the above cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "center-softball",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model1 = tf.keras.models.load_model('saved_models/retrain-yes/model1-imgnet-yesretrain.h5')\n",
    "# model2 = tf.keras.models.load_model('saved_models/retrain-yes/model2-imgnet-yesretrain.h5')\n",
    "# model3 = tf.keras.models.load_model('saved_models/retrain-yes/model3-imgnet-yesretrain.h5')\n",
    "# model4 = tf.keras.models.load_model('saved_models/retrain-yes/model4-imgnet-yesretrain.h5')\n",
    "# model5 = tf.keras.models.load_model('saved_models/retrain-yes/model5-imgnet-yesretrain.h5')\n",
    "\n",
    "# result_list = []\n",
    "# loss_list = []\n",
    "# accuracy_list = []\n",
    "\n",
    "# print(\"Retrain N-0 layers (ALL)\")\n",
    "# print(\"Evaluating split 1:\")\n",
    "# result1 = model1.evaluate(ds_test1)\n",
    "# result_list.append(result1)\n",
    "\n",
    "# print(\"\\nEvaluating split 2:\")\n",
    "# result2 = model2.evaluate(ds_test2)\n",
    "# result_list.append(result2)\n",
    "\n",
    "# print(\"\\nEvaluating split 3:\")\n",
    "# result3 = model3.evaluate(ds_test3)\n",
    "# result_list.append(result3)\n",
    "\n",
    "# print(\"\\nEvaluating split 4:\")\n",
    "# result4 = model4.evaluate(ds_test4)\n",
    "# result_list.append(result4)\n",
    "\n",
    "# print(\"\\nEvaluating split 5:\")\n",
    "# result5 = model5.evaluate(ds_test5)\n",
    "# result_list.append(result5)\n",
    "# for result in result_list:\n",
    "#     loss_list.append(result[0])\n",
    "#     accuracy_list.append(result[1])\n",
    "\n",
    "# print(\"\\n\\n\\nAverage Loss: \", sum(loss_list)/len(loss_list))\n",
    "# print(\"Average Accuracy: \", sum(accuracy_list)/len(accuracy_list))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
